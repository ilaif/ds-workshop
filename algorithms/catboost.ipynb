{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilaif/.virtualenvs/ds/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run ../modules.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Adding basic features...\n",
      "Done adding basic features.\n",
      "Adding image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilaif/Google Drive/uni/ds-workshop/Avito/utils/feature_enrichment.py:63: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/ilaif/Google Drive/uni/ds-workshop/Avito/utils/feature_enrichment.py:64: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading image features.\n",
      "Loading text features...\n",
      "loading tfidf features...\n",
      "Done loading text features.\n",
      "Loading aggregated features...\n",
      "Done loading aggregated features.\n",
      "Loading aggregated features...\n",
      "Done loading aggregated features.\n",
      "Cleaning and completing numeric features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilaif/Google Drive/uni/ds-workshop/Avito/utils/feature_enrichment.py:168: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/ilaif/Google Drive/uni/ds-workshop/Avito/utils/feature_enrichment.py:169: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cleaning numeric features.\n",
      "Completing image_top_1 features...\n",
      "Done loading image_top_1 completions.\n",
      "Completing price...\n",
      "Done loading log_price_regression.\n"
     ]
    }
   ],
   "source": [
    "init_data_paths(\"ilai\")\n",
    "print('loading data...')\n",
    "train, test = load_data(DATA_PATH)\n",
    "train, test = basic_enrichment(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_image_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_text_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = add_aggregated_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = numeric_features_cleaning(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = complete_image_top_1(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = complete_price(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "phase_1_train = train.copy()\n",
    "phase_1_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id',\n",
       " 'user_id',\n",
       " 'region',\n",
       " 'city',\n",
       " 'parent_category_name',\n",
       " 'category_name',\n",
       " 'param_1',\n",
       " 'param_2',\n",
       " 'param_3',\n",
       " 'title',\n",
       " 'description',\n",
       " 'price',\n",
       " 'item_seq_number',\n",
       " 'activation_date',\n",
       " 'user_type',\n",
       " 'image',\n",
       " 'image_top_1',\n",
       " 'deal_probability',\n",
       " 'has_description',\n",
       " 'has_price',\n",
       " 'has_params',\n",
       " 'has_image',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekday',\n",
       " 'user_ads_count',\n",
       " 'title_description_params',\n",
       " 'img_size',\n",
       " 'img_sharpness',\n",
       " 'img_luminance',\n",
       " 'img_colorfulness',\n",
       " 'img_confidence',\n",
       " 'img_keypoints',\n",
       " 'log_img_sharpness',\n",
       " 'log_img_keypoints',\n",
       " 'title_word_count',\n",
       " 'description_non_regular_chars_ratio',\n",
       " 'description_word_count',\n",
       " 'merged_params_word_count',\n",
       " 'description_sentence_count',\n",
       " 'description_words/sentence_ratio',\n",
       " 'title_capital_letters_ratio',\n",
       " 'description_capital_letters_ratio',\n",
       " 'title_non_regular_chars_ratio',\n",
       " 'title_num_of_newrow_char',\n",
       " 'description_num_of_newrow_char',\n",
       " 'title_num_adj',\n",
       " 'title_num_nouns',\n",
       " 'title_adj_to_len_ratio',\n",
       " 'title_noun_to_len_ratio',\n",
       " 'description_num_adj',\n",
       " 'description_num_nouns',\n",
       " 'description_adj_to_len_ratio',\n",
       " 'description_noun_to_len_ratio',\n",
       " 'title_first_noun_stemmed',\n",
       " 'title_second_noun_stemmed',\n",
       " 'title_third_noun_stemmed',\n",
       " 'description_first_noun_stemmed',\n",
       " 'description_second_noun_stemmed',\n",
       " 'description_third_noun_stemmed',\n",
       " 'title_first_adj_stemmed',\n",
       " 'title_second_adj_stemmed',\n",
       " 'title_third_adj_stemmed',\n",
       " 'description_first_adj_stemmed',\n",
       " 'description_second_adj_stemmed',\n",
       " 'description_third_adj_stemmed',\n",
       " 'title_sentiment',\n",
       " 'description_sentiment',\n",
       " 'title_svd_1_ngram',\n",
       " 'title_svd_2_ngram',\n",
       " 'title_svd_3_ngram',\n",
       " 'title_svd_4_ngram',\n",
       " 'title_svd_5_ngram',\n",
       " 'title_svd_6_ngram',\n",
       " 'title_svd_7_ngram',\n",
       " 'title_svd_8_ngram',\n",
       " 'title_svd_9_ngram',\n",
       " 'title_svd_10_ngram',\n",
       " 'title_svd_11_ngram',\n",
       " 'title_svd_12_ngram',\n",
       " 'title_svd_13_ngram',\n",
       " 'title_svd_14_ngram',\n",
       " 'title_svd_15_ngram',\n",
       " 'title_svd_16_ngram',\n",
       " 'title_svd_17_ngram',\n",
       " 'title_svd_18_ngram',\n",
       " 'title_svd_19_ngram',\n",
       " 'title_svd_20_ngram',\n",
       " 'title_svd_21_ngram',\n",
       " 'title_svd_22_ngram',\n",
       " 'title_svd_23_ngram',\n",
       " 'title_svd_24_ngram',\n",
       " 'title_svd_25_ngram',\n",
       " 'title_svd_26_ngram',\n",
       " 'title_svd_27_ngram',\n",
       " 'title_svd_28_ngram',\n",
       " 'title_svd_29_ngram',\n",
       " 'title_svd_30_ngram',\n",
       " 'description_svd_1_ngram',\n",
       " 'description_svd_2_ngram',\n",
       " 'description_svd_3_ngram',\n",
       " 'description_svd_4_ngram',\n",
       " 'description_svd_5_ngram',\n",
       " 'description_svd_6_ngram',\n",
       " 'description_svd_7_ngram',\n",
       " 'description_svd_8_ngram',\n",
       " 'description_svd_9_ngram',\n",
       " 'description_svd_10_ngram',\n",
       " 'description_svd_11_ngram',\n",
       " 'description_svd_12_ngram',\n",
       " 'description_svd_13_ngram',\n",
       " 'description_svd_14_ngram',\n",
       " 'description_svd_15_ngram',\n",
       " 'description_svd_16_ngram',\n",
       " 'description_svd_17_ngram',\n",
       " 'description_svd_18_ngram',\n",
       " 'description_svd_19_ngram',\n",
       " 'description_svd_20_ngram',\n",
       " 'description_svd_21_ngram',\n",
       " 'description_svd_22_ngram',\n",
       " 'description_svd_23_ngram',\n",
       " 'description_svd_24_ngram',\n",
       " 'description_svd_25_ngram',\n",
       " 'description_svd_26_ngram',\n",
       " 'description_svd_27_ngram',\n",
       " 'description_svd_28_ngram',\n",
       " 'description_svd_29_ngram',\n",
       " 'description_svd_30_ngram',\n",
       " 'avg_days_up_user',\n",
       " 'avg_times_up_user',\n",
       " 'n_user_items',\n",
       " 'log_item_seq_number',\n",
       " 'log_price',\n",
       " 'log_description_word_count',\n",
       " 'image_top_1_class',\n",
       " 'image_top_1_regression',\n",
       " 'image_top_1_rounded_regression',\n",
       " 'log_price_regression']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['user_type', \\\n",
    "                'region', 'city', \\\n",
    "                'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', \\\n",
    "                'image_top_1_class', 'image_top_1_rounded_regression', \\\n",
    "                'month', 'day', 'weekday', \\\n",
    "                'has_price', 'has_description', 'has_params', 'has_image',\n",
    "                   ]\n",
    "numerical_cols = ['image_top_1_regression', \\\n",
    "                     'log_price_regression', \\\n",
    "                     'avg_days_up_user', 'avg_times_up_user', 'n_user_items', 'user_ads_count', \\\n",
    "                     'log_item_seq_number', \\\n",
    "                     'img_size', 'img_luminance', 'img_colorfulness', 'img_confidence', 'log_img_sharpness', 'log_img_keypoints', \\\n",
    "                     'title_word_count', 'description_word_count', 'merged_params_word_count', \\\n",
    "                     'description_non_regular_chars_ratio', 'title_capital_letters_ratio','description_capital_letters_ratio', \\\n",
    "                     'title_non_regular_chars_ratio', 'title_adj_to_len_ratio', 'title_noun_to_len_ratio',\\\n",
    "                     'title_sentiment',\n",
    "                     'title_svd_1_ngram', 'title_svd_2_ngram', 'title_svd_3_ngram', 'title_svd_4_ngram', 'title_svd_5_ngram',\n",
    "                     'description_svd_1_ngram', 'description_svd_2_ngram', 'description_svd_3_ngram', 'description_svd_4_ngram', 'description_svd_5_ngram',\n",
    "                 ]\n",
    "\n",
    "feature_list = categorical_cols + numerical_cols\n",
    "\n",
    "def categorical_indices(df, categorical_cols):\n",
    "    return [i for i, col in enumerate(df.columns) if col in categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding user_type...\n",
      "Encoding region...\n",
      "Encoding city...\n",
      "Encoding parent_category_name...\n",
      "Encoding category_name...\n",
      "Encoding param_1...\n",
      "Encoding param_2...\n",
      "Encoding param_3...\n",
      "Encoding image_top_1_class...\n",
      "Encoding image_top_1_rounded_regression...\n",
      "Encoding month...\n",
      "Encoding day...\n",
      "Encoding weekday...\n",
      "Encoding has_price...\n",
      "Encoding has_description...\n",
      "Encoding has_params...\n",
      "Encoding has_image...\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "for col in categorical_cols:\n",
    "    print (\"Encoding \"+ str(col) + \"...\")\n",
    "    train[col] = train[col].astype('category')\n",
    "    test[col] = test[col].astype('category')\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n",
    "    train[col] = lbl.transform(list(train[col].values.astype('str')))\n",
    "    test[col] = lbl.transform(list(test[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = train[feature_list].fillna(0)\n",
    "y_df = train['deal_probability'].values\n",
    "X_test_df = test[feature_list].fillna(0)\n",
    "X_train_df, X_val_df, y_train_df, y_val_df = train_test_split(X_df, y_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2896994\ttest: 0.2892767\tbest: 0.2892767 (0)\ttotal: 7.84s\tremaining: 12m 56s\n",
      "50:\tlearn: 0.2283970\ttest: 0.2282178\tbest: 0.2282178 (50)\ttotal: 5m 19s\tremaining: 5m 7s\n",
      "\n",
      "bestTest = 0.2256196859\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x18a29af60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model = CatBoostRegressor(iterations=100,\n",
    "                             learning_rate=0.05,\n",
    "                             depth=12,\n",
    "                             eval_metric='RMSE',\n",
    "                             random_seed = 23,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 50,\n",
    "                             od_wait=100)\n",
    "cb_model.fit(X_train_df, y_train_df,\n",
    "             eval_set=(X_val_df, y_val_df),\n",
    "             cat_features=categorical_indices(X_val_df, categorical_cols),\n",
    "             use_best_model=True,\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22561837713086144\n"
     ]
    }
   ],
   "source": [
    "def test_catboost(cb_model, X_test, y_test):\n",
    "    y_pred = cb_model.predict(X_test)\n",
    "    y_pred = np.clip(y_pred, 0, 1)\n",
    "    res = rmse(y_pred, y_test)\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "results['catboost'] = { 'rmse': test_catboost(cb_model, X_val_df, y_val_df) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"catboost\": {\n",
      "    \"rmse\": 0.22561837713086144\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Submission Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cb_model.predict(X_test_df)\n",
    "y_pred = np.clip(y_pred, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(test['item_id'])\n",
    "res_df['deal_probability'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.271276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.198610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.198953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.176661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.272480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  deal_probability\n",
       "0  6544e41a8817          0.271276\n",
       "1  65b9484d670f          0.198610\n",
       "2  8bab230b2ecd          0.198953\n",
       "3  8e348601fefc          0.176661\n",
       "4  8bd2fe400b89          0.272480"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('../submissions/submit_res_catboost_%s.csv.gz' % datetime.datetime.now(), index=None, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost is much slower and brings inferior results to LGBM, we will not continue trials with it..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
