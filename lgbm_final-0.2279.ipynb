{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data_paths(\"final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "train, test = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding basic features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e709f05f5f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_enrichment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHELPER_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHELPER_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_text_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHELPER_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_aggregated_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHELPER_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_features_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHELPER_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/ds-workshop/feature_enrichment.py\u001b[0m in \u001b[0;36mbasic_enrichment\u001b[0;34m(train, test, helper_data_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mparam_3_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_3_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_3_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Merge Params to one text feature. Do not delete the params themselves.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/git/ds-workshop/feature_enrichment.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(param)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mparam_3_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_3_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_3_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Merge Params to one text feature. Do not delete the params themselves.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2555\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'getitem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# we can raise here if we are definitive that this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train, test = basic_enrichment(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_image_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = load_text_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = add_aggregated_features(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = numeric_features_cleaning(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = complete_image_top_1(train, test, helper_data_path=HELPER_DATA_PATH)\n",
    "train, test = complete_price(train, test, helper_data_path=HELPER_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:1000]\n",
    "test = test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['user_type', 'user_id', \\\n",
    "                    'region', 'city', \\\n",
    "                    'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', \\\n",
    "                    'image_top_1_class', 'image_top_1_rounded_regression', \\\n",
    "                    'month', 'day', 'weekday', \\\n",
    "                    'has_price', 'has_description', 'has_params', 'has_image'\n",
    "                   ]\n",
    "import gc\n",
    "gc.collect()\n",
    "for col in categorical_cols:\n",
    "    print (\"Encoding \"+ str(col) + \"...\")\n",
    "    train[col] = train[col].astype('category')\n",
    "    test[col] = test[col].astype('category')\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n",
    "    train[col] = lbl.transform(list(train[col].values.astype('str')))\n",
    "    test[col] = lbl.transform(list(test[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first started with a small group of features and we gradually added new features which were later created(text,image,aggregated features).</br>\n",
    "We then tried different groups of features and gradually eliminated redundant features - features with very low importance or that are highly correlated to other features or features that caused overfit and reduced our final validation score.</br>\n",
    "This are the final set of features we decided to use in our model (which gave us the best validation and test result)</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['user_type', 'user_id', \\\n",
    "                    'region', 'city', \\\n",
    "                    'parent_category_name', 'category_name', 'param_1', 'param_2', 'param_3', \\\n",
    "                    'image_top_1_class', \\\n",
    "                    'has_price', 'has_description', 'has_params', 'has_image',\n",
    "                   ]\n",
    "numerical_cols = [   'log_price_regression','avg_days_up_user', 'avg_times_up_user', 'n_user_items', \\\n",
    "                     'item_seq_number',\\\n",
    "                     'img_size', 'img_luminance', 'img_colorfulness', 'img_confidence', 'log_img_sharpness', 'log_img_keypoints', \\\n",
    "                     'title_word_count', 'description_word_count', 'merged_params_word_count', \\\n",
    "                     'words_vs_unique_title', 'words_vs_unique_description', \\\n",
    "                     'num_desc_punct', 'num_unique_words_description', 'num_unique_words_title', \\\n",
    "                     'title_svd_1_ngram',\n",
    "                     'title_svd_2_ngram',\n",
    "                     'title_svd_3_ngram',\n",
    "                     'title_svd_4_ngram',\n",
    "                     'title_svd_5_ngram',\n",
    "                     'title_svd_6_ngram',\n",
    "                     'title_svd_7_ngram',\n",
    "                     'title_svd_8_ngram',\n",
    "                     'title_svd_9_ngram',\n",
    "                     'title_svd_10_ngram',\n",
    "                     'title_svd_11_ngram',\n",
    "                     'title_svd_12_ngram',\n",
    "                     'title_svd_13_ngram',\n",
    "                     'title_svd_14_ngram',\n",
    "                     'title_svd_15_ngram',\n",
    "                     'title_svd_16_ngram',\n",
    "                     'title_svd_17_ngram',\n",
    "                     'title_svd_18_ngram',\n",
    "                     'title_svd_19_ngram',\n",
    "                     'title_svd_20_ngram',\n",
    "                     'title_svd_21_ngram',\n",
    "                     'title_svd_22_ngram',\n",
    "                     'title_svd_23_ngram',\n",
    "                     'title_svd_24_ngram',\n",
    "                     'title_svd_25_ngram',\n",
    "                     'title_svd_26_ngram',\n",
    "                     'title_svd_27_ngram',\n",
    "                     'title_svd_28_ngram',\n",
    "                     'title_svd_29_ngram',\n",
    "                     'title_svd_30_ngram',\n",
    "                     'description_svd_1_ngram',\n",
    "                     'description_svd_2_ngram',\n",
    "                     'description_svd_3_ngram',\n",
    "                     'description_svd_4_ngram',\n",
    "                     'description_svd_5_ngram',\n",
    "                     'description_svd_6_ngram',\n",
    "                     'description_svd_7_ngram',\n",
    "                     'description_svd_8_ngram',\n",
    "                     'description_svd_9_ngram',\n",
    "                     'description_svd_10_ngram',\n",
    "                     'description_svd_11_ngram',\n",
    "                     'description_svd_12_ngram',\n",
    "                     'description_svd_13_ngram',\n",
    "                     'description_svd_14_ngram',\n",
    "                     'description_svd_15_ngram',\n",
    "                     'description_svd_16_ngram',\n",
    "                     'description_svd_17_ngram',\n",
    "                     'description_svd_18_ngram',\n",
    "                     'description_svd_19_ngram',\n",
    "                     'description_svd_20_ngram',\n",
    "                     'description_svd_21_ngram',\n",
    "                     'description_svd_22_ngram',\n",
    "                     'description_svd_23_ngram',\n",
    "                     'description_svd_24_ngram',\n",
    "                     'description_svd_25_ngram',\n",
    "                     'description_svd_26_ngram',\n",
    "                     'description_svd_27_ngram',\n",
    "                     'description_svd_28_ngram',\n",
    "                     'description_svd_29_ngram',\n",
    "                     'description_svd_30_ngram', \n",
    "                 ]\n",
    "\n",
    "feature_list = categorical_cols + numerical_cols + ['item_id']\n",
    "\n",
    "def categorical_indices(df, categorical_cols):\n",
    "    return [i for i, col in enumerate(df.columns) if col in categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = train[feature_list].fillna(0)\n",
    "y_df = train['deal_probability'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = test[feature_list].fillna(0)\n",
    "X_train_df, X_val_df, y_train_df, y_val_df = train_test_split(X_df, y_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_item_id = X_train_df[['item_id']]\n",
    "X_test_item_id = X_test_df[['item_id']]\n",
    "X_val_item_id = X_val_df[['item_id']]\n",
    "del X_train_df['item_id']\n",
    "del X_test_df['item_id']\n",
    "del X_val_df['item_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
    "* https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try both regression and poisson objectives in the ensemble model, so we train both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 'regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with the parameters we received from the hyperparmeter tuning and we gradually increased the number of leaves and decreased the learning rate (the number of leaves increases the model complexity and to avoid overfit we reduce the learning rate and use high number of training rounds) until our score stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_idx = categorical_indices(X_df, categorical_cols)\n",
    "lgb_train = lgb.Dataset(X_train_df, label=y_train_df)\n",
    "lgb_val = lgb.Dataset(X_val_df, y_val_df, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': objective,\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 15,\n",
    "    'num_leaves': 512,\n",
    "    'num_estimators':38,\n",
    "    'feature_fraction': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'ransom_state':[501],\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "def train_lgb(my_params, my_lgb_train, my_lgb_val):\n",
    "    evals_result = {}\n",
    "    clf = lgb.train(my_params, \n",
    "                    my_lgb_train, \n",
    "                    num_boost_round=4000,\n",
    "                    valid_sets=[my_lgb_train, my_lgb_val],\n",
    "                    early_stopping_rounds=200,\n",
    "                    feature_name=feature_list[:-1],\n",
    "                    categorical_feature=categorical_features_idx,\n",
    "                    evals_result=evals_result,\n",
    "                    verbose_eval=200)\n",
    "    return clf, evals_result\n",
    "\n",
    "clf, evals_result = train_lgb(params, lgb_train, lgb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lgb(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test, num_iteration= clf.best_iteration)\n",
    "    y_pred = np.clip(y_pred, 0, 1)\n",
    "    res = rmse(y_pred, y_test)\n",
    "    print(res)\n",
    "    return res\n",
    "gc.collect()\n",
    "results = {}\n",
    "results['lgbm'] = { 'rmse': test_lgb(clf, X_val_df, y_val_df) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lgbm_result():\n",
    "    print('Plot metrics during training...')\n",
    "    ax = lgb.plot_metric(evals_result, metric='rmse')\n",
    "    plt.title(\"Light GBM Metrics\")\n",
    "    plt.show()\n",
    "\n",
    "    print('Plot feature importances...')\n",
    "    fig, ax = plt.subplots(figsize=(10, 14))\n",
    "    lgb.plot_importance(clf, max_num_features=80, ax=ax)\n",
    "    plt.title(\"Light GBM Feature Importance\")\n",
    "    plt.show()\n",
    "\n",
    "#     print('Plot 84th tree...')  # one tree use categorical feature to split\n",
    "#     ax = lgb.plot_tree(clf, tree_index=83, figsize=(20, 8), show_info=['split_gain'])\n",
    "#     plt.show()\n",
    "\n",
    "#     print('Plot 84th tree with graphviz...')\n",
    "# #     graph = lgb.create_tree_digraph(clf, tree_index=83, name='Tree84')\n",
    "# #     graph.render(view=True)\n",
    "    \n",
    "analyze_lgbm_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Submission Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_df)\n",
    "y_pred = np.clip(y_pred, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(test['item_id'])\n",
    "res_df['deal_probability'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('../submissions/submit_res_lgbm_%s_15.csv.gz' % objective, index=None, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions on all data to unify with an ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train_df)\n",
    "res_train_df = pd.DataFrame(X_train_item_id['item_id'])\n",
    "res_train_df['deal_probability'] = y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = clf.predict(X_val_df)\n",
    "res_val_df = pd.DataFrame(X_val_item_id['item_id'])\n",
    "res_val_df['deal_probability'] = y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test_df)\n",
    "res_test_df = pd.DataFrame(X_test_item_id['item_id'])\n",
    "res_test_df['deal_probability'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res_train_df, res_val_df, res_test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../all_data_lgbm_%s_results_0.2281.csv.gz' % objective, index=None, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.clip(y_pred, 0, 1)\n",
    "X_val_df['pred_dp'] = y_pred\n",
    "X_val_df['real_dp'] = y_val_df\n",
    "X_val_df['mistake'] = np.abs(y_val_df - y_pred)\n",
    "bad_df = X_val_df.sort_values(by='mistake', ascending=False).iloc[:25000]\n",
    "good_df = X_val_df.sort_values(by='mistake', ascending=True).iloc[:25000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might wish to predict high price and low price seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type_dist = good_df.groupby('user_type').size()\n",
    "explode = (0.15, 0, 0)\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "labels = user_type_dist.index\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(user_type_dist, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.title('User types by percentage Good')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type_dist = bad_df.groupby('user_type').size()\n",
    "explode = (0.15, 0, 0)\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "labels = user_type_dist.index\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(user_type_dist, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.title('User types by percentage Bad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_type_dist = X_df.groupby('user_type').size()\n",
    "explode = (0.15, 0, 0)\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "labels = user_type_dist.index\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(user_type_dist, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.title('User types by percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have higher success rate on the smaller classes of user types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = good_df.groupby('category_name').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.title('Number of items per category Good')\n",
    "plt.show()\n",
    "category_counts = good_df.groupby('parent_category_name').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.title('Number of items per parent category Good')\n",
    "plt.show()\n",
    "\n",
    "parent_category_dist = good_df.groupby('parent_category_name').size()\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "labels = parent_category_dist.index\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(parent_category_dist, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.title('Parent categories by percentage Good')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = bad_df.groupby('category_name').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.title('Number of items per category Bad')\n",
    "plt.show()\n",
    "category_counts = bad_df.groupby('parent_category_name').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.title('Number of items per parent category Bad')\n",
    "plt.show()\n",
    "\n",
    "parent_category_dist = bad_df.groupby('parent_category_name').size()\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "labels = parent_category_dist.index\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(parent_category_dist, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.title('Parent categories by percentage Bad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = X_df.groupby('category_name').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.title('Number of items per category')\n",
    "plt.show()\n",
    "category_counts = X_df.groupby('parent_category_name').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "plt.title('Number of items per parent category')\n",
    "plt.show()\n",
    "\n",
    "parent_category_dist = X_df.groupby('parent_category_name').size()\n",
    "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99']\n",
    "labels = parent_category_dist.index\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(parent_category_dist, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.title('Parent categories by percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't predict well categories 0,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = good_df.groupby('region').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(region_counts.index, region_counts.values)\n",
    "plt.title('Number of items per region Good')\n",
    "plt.show()\n",
    "city_counts = good_df.groupby('city').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(city_counts.index, city_counts.values)\n",
    "plt.title('Number of items per city Good')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = bad_df.groupby('region').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(region_counts.index, region_counts.values)\n",
    "plt.title('Number of items per region Bad')\n",
    "plt.show()\n",
    "city_counts = bad_df.groupby('city').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(city_counts.index, city_counts.values)\n",
    "plt.title('Number of items per city Bad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = X_df.groupby('region').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(region_counts.index, region_counts.values)\n",
    "plt.title('Number of items per region')\n",
    "plt.show()\n",
    "city_counts = X_df.groupby('city').size().sort_values(ascending=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(city_counts.index, city_counts.values)\n",
    "plt.title('Number of items per city')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
