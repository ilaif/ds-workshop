{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "\n",
    "In other notebooks we've trained various models on our train data and saved the predictions for those models on both our train and test sets.\n",
    "\n",
    "In this notebook we train two ensembling models, a meta-network (for non linear ensembling) and a lasso regression model (for linear ensembling), that get as input the predictions of all other models and give the final prediction as an output. Obviously we train those models on the y labels (probability scores) of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018/intelpython3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run stephan_modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "PREDICTIONS_DATA_PATH = './predictions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "train, test = load_data(DATA_PATH)\n",
    "\n",
    "train_items = pd.DataFrame(train['item_id'])\n",
    "test_items = pd.DataFrame(test['item_id'])\n",
    "train_expected = train['deal_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predcictions for:NN-COUNTVEC-MERGED-BIGRAMS.csv.gz\n",
      "Loading predcictions for:NN-COUNTVEC-MERGED-UNI-nodropout.csv.gz\n",
      "Loading predcictions for:NN-COUNTVEC-SEPARATED-BIGRAMS-nodropout.csv.gz\n",
      "Loading predcictions for:NN-COUNTVEC-SEPARATED-UNIGRAMS.csv.gz\n",
      "Loading predcictions for:NN-TFIDF-MERGED-BIGRAMS.csv.gz\n",
      "Loading predcictions for:NN-TFIDF-SEPARATED-BIGRAMS-nodropout.csv.gz\n",
      "Loading predcictions for:NN-TFIDF-SEPARATED-UNIGRAMS.csv.gz\n",
      "Loading predcictions for:NN-TFIDF-UNI-MERGED-nodropout.csv.gz\n",
      "Loading predcictions for:all_data_lgbm_regression_results_0.2281.csv.gz\n",
      "Loading predcictions for:all_data_lgbm_poisson_results_0.2281.csv.gz\n",
      "Loading predcictions for:NN-JUST-LSTM-MERGED.csv.gz\n",
      "Loading predcictions for:NN-LSTM-COMBINED-MERGED.csv.gz\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "file_names = ['NN-COUNTVEC-MERGED-BIGRAMS.csv.gz',\n",
    "              'NN-COUNTVEC-MERGED-UNI-nodropout.csv.gz',\n",
    "              'NN-COUNTVEC-SEPARATED-BIGRAMS-nodropout.csv.gz',\n",
    "              'NN-COUNTVEC-SEPARATED-UNIGRAMS.csv.gz',\n",
    "              'NN-TFIDF-MERGED-BIGRAMS.csv.gz',\n",
    "              'NN-TFIDF-SEPARATED-BIGRAMS-nodropout.csv.gz',\n",
    "              'NN-TFIDF-SEPARATED-UNIGRAMS.csv.gz',\n",
    "              'NN-TFIDF-UNI-MERGED-nodropout.csv.gz',              \n",
    "              'all_data_lgbm_regression_results_0.2281.csv.gz',\n",
    "              'all_data_lgbm_poisson_results_0.2281.csv.gz',\n",
    "              'NN-JUST-LSTM-MERGED.csv.gz',\n",
    "              'NN-LSTM-COMBINED-MERGED.csv.gz']\n",
    "\n",
    "\n",
    "for filename in file_names:\n",
    "    print(\"Loading predcictions for:{}\".format(filename))\n",
    "    predictions = load_df(PREDICTIONS_DATA_PATH, filename)\n",
    "    model_name = 'model_' + filename\n",
    "    predictions = predictions.rename({'deal_probability': model_name}, axis='columns')            \n",
    "    train_items = train_items.merge(predictions, on='item_id', how='left')\n",
    "    test_items = test_items.merge(predictions, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id',\n",
       " 'model_NN-COUNTVEC-MERGED-BIGRAMS.csv.gz',\n",
       " 'model_NN-COUNTVEC-MERGED-UNI-nodropout.csv.gz',\n",
       " 'model_NN-COUNTVEC-SEPARATED-BIGRAMS-nodropout.csv.gz',\n",
       " 'model_NN-COUNTVEC-SEPARATED-UNIGRAMS.csv.gz',\n",
       " 'model_NN-TFIDF-MERGED-BIGRAMS.csv.gz',\n",
       " 'model_NN-TFIDF-SEPARATED-BIGRAMS-nodropout.csv.gz',\n",
       " 'model_NN-TFIDF-SEPARATED-UNIGRAMS.csv.gz',\n",
       " 'model_NN-TFIDF-UNI-MERGED-nodropout.csv.gz',\n",
       " 'model_all_data_lgbm_regression_results_0.2281.csv.gz',\n",
       " 'model_all_data_lgbm_poisson_results_0.2281.csv.gz',\n",
       " 'model_NN-JUST-LSTM-MERGED.csv.gz',\n",
       " 'model_NN-LSTM-COMBINED-MERGED.csv.gz']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items.drop(['item_id'], axis=1, inplace=True)\n",
    "test_items.drop(['item_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling through a Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim1 = 128\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_predictions (InputLaye (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "hidden_dim1 (Dense)          (None, 128)               1664      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,793\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "l_input = Input(shape=(train_items.shape[1],), name=\"input_predictions\")\n",
    "do1 = Dropout(0.2)(l_input)\n",
    "hidden_dim = Dense(hidden_dim1, activation='linear', kernel_regularizer=regularizers.l1(1e-3), name='hidden_dim1')(do1)\n",
    "do2 = Dropout(0.2)(hidden_dim)\n",
    "output = Dense(out_dim, activation='sigmoid', kernel_regularizer=regularizers.l1(1e-3), name='output')(do2)\n",
    "\n",
    "adam_opt = Adam(lr=0.001)\n",
    "def rmse_err(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "model = Model(l_input, output)\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss=[rmse_err])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1503424/1503424 [==============================] - 8s 6us/step - loss: 0.2427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15308fec4c50>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbatch_size = 1024\n",
    "model.fit(train_items, train_expected,\n",
    "          #validation_split = 0.3, \n",
    "          epochs=1, \n",
    "          batch_size=nbatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NN submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.194396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.108244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.177688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.120174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.130631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  deal_probability\n",
       "0  6544e41a8817          0.194396\n",
       "1  65b9484d670f          0.108244\n",
       "2  8bab230b2ecd          0.177688\n",
       "3  8e348601fefc          0.120174\n",
       "4  8bd2fe400b89          0.130631"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.clip(y_pred, 0, 1)\n",
    "res_df = pd.DataFrame(test['item_id'])\n",
    "res_df['deal_probability'] = y_pred\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('./submissions/NN_ensemble_res_%s.csv.gz' % datetime.datetime.now(), index=None, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define lasso regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_model = Lasso(alpha=0.0001, precompute=True, max_iter=1000, positive=True, random_state=9999, selection='random')\n",
    "lasso_model.fit(train_items, train_expected)\n",
    "y_pred = lasso_model.predict(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.279048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.104908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.210024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.144640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.102979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  deal_probability\n",
       "0  6544e41a8817          0.279048\n",
       "1  65b9484d670f          0.104908\n",
       "2  8bab230b2ecd          0.210024\n",
       "3  8e348601fefc          0.144640\n",
       "4  8bd2fe400b89          0.102979"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.clip(y_pred, 0, 1)\n",
    "res_df = pd.DataFrame(test['item_id'])\n",
    "res_df['deal_probability'] = y_pred\n",
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('./submissions/Lasso_regression_ensemble_res_%s.csv.gz' % datetime.datetime.now(), index=None, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
